{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "17EZ4WZjmAZN-ekU2hgLpx8V3E8iMcRLv",
      "authorship_tag": "ABX9TyPf9Y6a2BUhPUc6RW84AgZV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ikeda33/codespaces-railstutorial/blob/main/cycleGAN_local_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ローカルのGPUに繋げる\n",
        "#jupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com' --port=8889 --NotebookApp.port_retries=0 --NotebookApp.iopub_data_rate_limit 10000000"
      ],
      "metadata": {
        "id": "ZnMT1Pbq1f-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23wf04cpc3vN"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import glob\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import tqdm\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--n_epoch\", type = int, default=50)\n",
        "parser.add_argument(\"--batch_size\", type = int, default=1)\n",
        "parser.add_argument(\"--lr\", type = float, default=3e-4)\n",
        "parser.add_argument(\"--decay_start\", type = int, default=100)\n",
        "parser.add_argument(\"--weight_identity\", type = float, default=5.0)\n",
        "parser.add_argument(\"--weight_cycle\", type = float, default=10.0)\n",
        "\n",
        "parser.add_argument(\"--image_size\", type = int, default=256)\n",
        "parser.add_argument(\"--n_ch\", type = int, default=64)\n",
        "\n",
        "parser.add_argument(\"--z_dim\", type = int, default=100)\n",
        "parser.add_argument(\"--beta1\", type = float, default=0.5)\n",
        "\n",
        "opt = parser.parse_args(args=[])\n",
        "print(opt)"
      ],
      "metadata": {
        "id": "6Ru7JWlB8A00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e01e947c-3bcf-46a8-a582-07b43e42ed6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(n_epoch=50, batch_size=1, lr=0.0003, decay_start=100, weight_identity=5.0, weight_cycle=10.0, image_size=256, n_ch=64, z_dim=100, beta1=0.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#localの時は消す"
      ],
      "metadata": {
        "id": "wBaJxH5d-Zyt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "592ca65a-3b23-4d78-e967-e828e3915942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"from google.colab import drive\\ndrive.mount('/content/drive')\""
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HMdU591P_WV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self,  transform = None):\n",
        "        super().__init__()\n",
        "        #self.files_A = glob.glob(\"/content/drive/MyDrive/horse2zebra (1)/horse2zebra/trainA/*.jpg\")#colab\n",
        "        #self.files_B = glob.glob(\"/content/drive/MyDrive/horse2zebra (1)/horse2zebra/trainB/*.jpg\")#colab\n",
        "        self.files_A = glob.glob(R\"C:\\Users\\ikeda\\Downloads\\horse2zebra (1)\\horse2zebra\\trainA\\*.jpg\")#local \"C:\\Users\\ikeda\\Downloads\\horse2zebra (1)\\horse2zebra\\trainA\\n02381460_2.jpg\"\n",
        "        self.files_B = glob.glob(R\"C:\\Users\\ikeda\\Downloads\\horse2zebra (1)\\horse2zebra\\trainB\\*.jpg\")#local\n",
        "\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "      imgA = self.transform(Image.open(self.files_A[index % len(self.files_A)]))\n",
        "      while True:\n",
        "        random_index = np.random.randint(0, len(self.files_B) - 1)\n",
        "        imgB = self.transform(Image.open(self.files_B[random_index % len(self.files_B)]))\n",
        "        C, H, W = imgB.size()\n",
        "        if C == 3:\n",
        "          break\n",
        "      return {\"A\":imgA, \"B\":imgB}\n",
        "\n",
        "    \n",
        "    def __len__(self):\n",
        "        return max(len(self.files_A), len(self.files_B))"
      ],
      "metadata": {
        "id": "FxsgIvst_AiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecayLR(object):\n",
        "  def __init__(self, n_epoch, offset, decay_start_epoch):\n",
        "    self.n_epoch = n_epoch\n",
        "    self.offset = offset\n",
        "    self.decay_start_epoch = decay_start_epoch\n",
        "\n",
        "  def step(self, epoch):\n",
        "    return 1.0 - max(0, epoch + self.offset -self.decay_start_epoch)/(self.n_epoch - self.decay_start_epoch)"
      ],
      "metadata": {
        "id": "KQvrIE8dEleD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayBuffer:\n",
        "  def __init__(self, max_size = 50):\n",
        "    self.max_size = max_size\n",
        "    self.data = []\n",
        "\n",
        "  def push_and_pop(self, data):\n",
        "    to_return = []\n",
        "    for element in data.data:\n",
        "      element = torch.unsqueeze(element, 0)\n",
        "      if len(self.data) < self.max_size:\n",
        "        self.data.append(element)\n",
        "        to_return.append(element)\n",
        "      else:\n",
        "        if np.random.rand() > 0.5:\n",
        "          i = np.random.randint(0, self.max_size - 1)\n",
        "          to_return.append(self.data[i].clone())\n",
        "          self.data[i] = element\n",
        "        else:\n",
        "          to_return.append(element)\n",
        "    return torch.cat(to_return)\n",
        "    "
      ],
      "metadata": {
        "id": "VSUZc77FGZe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, in_channels):\n",
        "    super().__init__()\n",
        "    self.conv_layers = nn.Sequential(\n",
        "        nn.ReflectionPad2d(1),\n",
        "        nn.Conv2d(in_channels, in_channels, 3),\n",
        "        nn.InstanceNorm2d(in_channels),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.ReflectionPad2d(1),\n",
        "        nn.Conv2d(in_channels, in_channels, 3),\n",
        "        nn.InstanceNorm2d(in_channels),\n",
        "        \n",
        "    )\n",
        "  def forward(self, x):\n",
        "    out = self.conv_layers(x)\n",
        "    out = out + x\n",
        "    return out"
      ],
      "metadata": {
        "id": "YgIS1lchLXfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, res_block, in_channels = 3, n_ch = opt.n_ch):\n",
        "    super().__init__()\n",
        "    self.encoder = nn.Sequential(\n",
        "        nn.ReflectionPad2d(3),\n",
        "        nn.Conv2d(in_channels,n_ch, 7),\n",
        "        nn.InstanceNorm2d(n_ch),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.Conv2d(n_ch,n_ch * 2, 3, stride = 2, padding = 1),\n",
        "        nn.InstanceNorm2d(n_ch * 2),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.Conv2d(n_ch * 2,n_ch * 4, 3, stride = 2, padding = 1),\n",
        "        nn.InstanceNorm2d(n_ch * 4),\n",
        "        nn.ReLU(inplace=True),    \n",
        "    )\n",
        "    #transformer\n",
        "    self.res_block = res_block(n_ch * 4)\n",
        "    self.transformer = nn.ModuleList([\n",
        "            res_block(n_ch * 4), \n",
        "            res_block(n_ch * 4), \n",
        "            res_block(n_ch * 4), \n",
        "            res_block(n_ch * 4), \n",
        "            res_block(n_ch * 4), \n",
        "            res_block(n_ch * 4), \n",
        "            res_block(n_ch * 4), \n",
        "            res_block(n_ch * 4), \n",
        "            res_block(n_ch * 4),                     \n",
        "    ])\n",
        "    self.decoder = nn.Sequential(\n",
        "        nn.ConvTranspose2d(n_ch * 4, n_ch * 2, 3, stride = 2, padding = 1, output_padding=1),\n",
        "        nn.InstanceNorm2d(n_ch * 2),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.ConvTranspose2d(n_ch * 2, n_ch , 3, stride = 2, padding = 1, output_padding=1),\n",
        "        nn.InstanceNorm2d(n_ch),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.ReflectionPad2d(3),\n",
        "        nn.Conv2d(n_ch, 3, 7),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.encoder(x)\n",
        "    for func in self.transformer:\n",
        "      out = func(out)\n",
        "    out = self.decoder(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "svvAkiGcZWkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, n_ch = opt.n_ch):\n",
        "    super().__init__()\n",
        "    self.conv1 = self.conv_layer(3, n_ch, 4, 2, 1)\n",
        "    self.conv2 = self.conv_layer(n_ch, n_ch*2, 4, 2, 1)\n",
        "    self.conv3 = self.conv_layer(n_ch*2, n_ch*4, 4, 2, 1)\n",
        "    self.conv4 = self.conv_layer(n_ch*4, n_ch*8, 4, 1, 1)\n",
        "    self.conv5 = nn.Conv2d(n_ch*8, 1,   4, 1,padding = 1)\n",
        "\n",
        "  @staticmethod\n",
        "  def conv_layer(in_channels, out_channels, kernel_size, stride, padding, has_norm= True):\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)]\n",
        "    if has_norm == True:\n",
        "      layers.append(nn.InstanceNorm2d(out_channels))\n",
        "    layers.append(nn.LeakyReLU(0.2, inplace =True))\n",
        "    net = nn.Sequential(*layers)\n",
        "    return net\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.conv1(x)\n",
        "    out = self.conv2(out)\n",
        "    out = self.conv3(out)\n",
        "    out = self.conv4(out)\n",
        "    out = self.conv5(out)\n",
        "    B, C, H, W = out.size()\n",
        "    out = F.avg_pool2d(out, (H, W))# squeeze->imagesize = 1*1\n",
        "    out = out.view(B, -1)#-> 1dimension\n",
        "    return out"
      ],
      "metadata": {
        "id": "yQjS4qb0f9g4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Conv\") != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find(\"BatchNorm\") != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "        "
      ],
      "metadata": {
        "id": "KPe8MLGflkax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torchvision.transforms.transforms import CenterCrop\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    \n",
        "    transforms.Resize(int(opt.image_size * 1.12), Image.BICUBIC),#Image.BICUBIC は画像の互換法\n",
        "    transforms.RandomCrop(opt.image_size),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(), \n",
        "    transforms.Normalize((0.5,),(0.5,))])"
      ],
      "metadata": {
        "id": "89fNnAY0l71Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fb98f7d-9411-4b05-e05b-93472c85cb1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\ikeda\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py:332: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ImageDataset(transform = transform)"
      ],
      "metadata": {
        "id": "fhaqrFewnMMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset = dataset, batch_size = opt.batch_size,num_workers = 2,  shuffle = True)#データの読み込み"
      ],
      "metadata": {
        "id": "JFTFD9OmnMQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "aZ3Oq1_bncvq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3d9b623-094f-4b43-8428-b7a857bf9151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "netG_A2B = Generator(ResidualBlock).to(device)\n",
        "netG_A2B.apply(weights_init)\n",
        "\n",
        "netG_B2A = Generator(ResidualBlock).to(device)\n",
        "netG_B2A.apply(weights_init)\n",
        "\n",
        "netD_A = Discriminator().to(device)\n",
        "netD_A.apply(weights_init)\n",
        "\n",
        "netD_B = Discriminator().to(device)\n",
        "netD_B.apply(weights_init)\n"
      ],
      "metadata": {
        "id": "gJdTAT7vnoaW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eaacf39-34dd-48dc-cb8d-87ea20dbe6e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (conv3): Sequential(\n",
              "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (conv4): Sequential(\n",
              "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
              "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (conv5): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adversarial_loss = torch.nn.MSELoss().to(device)\n",
        "cycle_loss = torch.nn.L1Loss().to(device)\n",
        "identity_loss = torch.nn.L1Loss().to(device)"
      ],
      "metadata": {
        "id": "USb1AF9Io9Vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_D_A = optim.Adam(netD_A.parameters(), lr = opt.lr, betas = (opt.beta1, 0.999))\n",
        "optimizer_D_B = optim.Adam(netD_B.parameters(), lr = opt.lr, betas = (opt.beta1, 0.999))\n",
        "\n",
        "optimizer_G = optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()), lr = opt.lr, betas = (opt.beta1, 0.999))#二つの生成器を同時に最適化\n"
      ],
      "metadata": {
        "id": "GAue_6wTqLWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_lambda = DecayLR(opt.n_epoch, 0, opt.decay_start).step\n",
        "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda = lr_lambda)\n",
        "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda = lr_lambda)\n",
        "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda = lr_lambda)\n"
      ],
      "metadata": {
        "id": "0jdomkzmrdZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"#出力のためのディレクトリ\n",
        "import os\n",
        "\n",
        "model_name = \"CycleGAN\"\n",
        "f_path_params = \"/content/drive/MyDrive/params/{}\".format(model_name)\n",
        "f_path_result  = \"/content/drive/MyDrive/result/{}\".format(model_name)\n",
        "\n",
        "os.makedirs(f_path_result, exist_ok = True)\n",
        "os.makedirs(f_path_params, exist_ok = True)\n",
        "\"\"\"\n",
        "#colab"
      ],
      "metadata": {
        "id": "vfQMVIqt_Fcs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2203fb5d-c191-40c1-a5ab-1da2fc863d27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'#出力のためのディレクトリ\\nimport os\\n\\nmodel_name = \"CycleGAN\"\\nf_path_params = \"/content/drive/MyDrive/params/{}\".format(model_name)\\nf_path_result  = \"/content/drive/MyDrive/result/{}\".format(model_name)\\n\\nos.makedirs(f_path_result, exist_ok = True)\\nos.makedirs(f_path_params, exist_ok = True)\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"#パラメータ保存\n",
        "def save_params(epoch, dir_path, model_list, model_name_list):\n",
        "  for model, model_name in zip(model_list, model_name_list):\n",
        "    file_path = dir_path + \"/{model}_{epoch}.pth\".format(model = model_name, epoch = epoch)\n",
        "    torch.save(model.state_dict(), file_path)\"\"\"\n",
        "  #colab"
      ],
      "metadata": {
        "id": "7LPYrtrtAfhe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fc8b40d-57cb-4a45-9cf8-c84bea81b76e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'#パラメータ保存\\ndef save_params(epoch, dir_path, model_list, model_name_list):\\n  for model, model_name in zip(model_list, model_name_list):\\n    file_path = dir_path + \"/{model}_{epoch}.pth\".format(model = model_name, epoch = epoch)\\n    torch.save(model.state_dict(), file_path)'"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fake_A_buffer = ReplayBuffer()\n",
        "fake_B_buffer = ReplayBuffer()\n",
        "\n",
        "for epoch in range(0, opt.n_epoch):\n",
        "  running_loss_D = 0.0\n",
        "  running_loss_G = 0.0\n",
        "  running_loss_G_GAN = 0.0\n",
        "  running_loss_G_cycle = 0.0\n",
        "  running_loss_G_identity = 0.0\n",
        "\n",
        "  for data in tqdm.tqdm(dataloader, position = 0):\n",
        "\n",
        "    real_img_A = data[\"A\"].to(device)\n",
        "    real_img_B = data[\"B\"].to(device)\n",
        "\n",
        "    batch_size = real_img_A.size()[0]\n",
        "\n",
        "    real_label = torch.ones([batch_size, 1]).to(device)#use generator loss\n",
        "    fake_label = torch.zeros([batch_size, 1]).to(device)\n",
        "\n",
        "    #train_generator\n",
        "    optimizer_G.zero_grad()#勾配初期化\n",
        "    #adversarial loss\n",
        "    fake_img_A = netG_B2A(real_img_B)\n",
        "    fake_img_B = netG_A2B(real_img_A)\n",
        "\n",
        "    output_A = netD_A(fake_img_A)\n",
        "    output_B = netD_B(fake_img_B)\n",
        "\n",
        "    loss_GAN_A2B = adversarial_loss(output_B, real_label)#本物と判別されたいから ->real_label\n",
        "    loss_GAN_B2A = adversarial_loss(output_A, real_label)\n",
        "    #cycle loss\n",
        "    cycle_img_A = netG_B2A(fake_img_B)\n",
        "    cycle_img_B = netG_A2B(fake_img_A)\n",
        "\n",
        "    loss_cycle_ABA = cycle_loss(cycle_img_A, real_img_A)\n",
        "    loss_cycle_BAB = cycle_loss(cycle_img_B, real_img_A)\n",
        "    #identity loss\n",
        "    identity_img_A = netG_B2A(real_img_A)\n",
        "    identity_img_B = netG_A2B(real_img_B)\n",
        "\n",
        "    loss_identity_A = identity_loss(identity_img_A, real_img_A)\n",
        "    loss_identity_B = identity_loss(identity_img_B, real_img_B)\n",
        "\n",
        "    lossG = (loss_GAN_A2B +loss_GAN_B2A + \n",
        "             opt.weight_cycle * (loss_cycle_ABA +loss_cycle_BAB) + \n",
        "             opt.weight_identity *  (loss_identity_A + loss_identity_B))\n",
        "    \n",
        "    lossG.backward()\n",
        "    optimizer_G.step()\n",
        "\n",
        "    #train discriminator\n",
        "    optimizer_D_A.zero_grad()\n",
        "    optimizer_D_B.zero_grad()\n",
        "#実際の画像から損失を計算\n",
        "    real_output_A = netD_A(real_img_A)\n",
        "    real_output_B = netD_B(real_img_B)\n",
        "\n",
        "    loss_DA_real = adversarial_loss(real_output_A, real_label)\n",
        "    loss_DB_real = adversarial_loss(real_output_B, real_label)\n",
        "    #偽物の画像から損失を計算する\n",
        "    fake_img_A  = fake_A_buffer.push_and_pop(fake_img_A)#5０枚のバッファを超えてくると確率的に古い偽物画像が送られる\n",
        "    fake_img_B  = fake_B_buffer.push_and_pop(fake_img_B)\n",
        "\n",
        "    fake_output_A = netD_A(fake_img_A.detach())\n",
        "    fake_output_B = netD_B(fake_img_B.detach())\n",
        "\n",
        "    loss_DA_fake = adversarial_loss(fake_output_A, fake_label)\n",
        "    loss_DB_fake = adversarial_loss(fake_output_B, fake_label)\n",
        "\n",
        "    loss_DA = (loss_DA_real +loss_DA_fake )*0.5\n",
        "    loss_DB = (loss_DB_real +loss_DB_fake )*0.5\n",
        "\n",
        "    loss_DA.backward()\n",
        "    loss_DB.backward()\n",
        "    optimizer_D_A.step()\n",
        "    optimizer_D_B.step()\n",
        "    #adding to running loss\n",
        "    running_loss_D += (loss_DA.item() + loss_DB.item())/2.0\n",
        "    running_loss_G += lossG.item()\n",
        "\n",
        "    running_loss_G_GAN += (loss_GAN_A2B.item() + loss_GAN_B2A.item()) / 2.0\n",
        "    running_loss_G_cycle += (loss_cycle_ABA.item() + loss_cycle_BAB.item()) / 2.0\n",
        "    running_loss_G_identity += (loss_identity_A.item() + loss_identity_B.item()) / 2.0\n",
        "  lr_scheduler_G.step()\n",
        "  lr_scheduler_D_A.step()\n",
        "  lr_scheduler_D_B.step()\n",
        "  running_loss_D /= len(dataloader)\n",
        "  running_loss_G /= len(dataloader)\n",
        "  running_loss_G_GAN/= len(dataloader)\n",
        "  running_loss_G_cycle /= len(dataloader)\n",
        "  running_loss_G_identity/= len(dataloader)\n",
        "  loss_log = \"\"\"\n",
        "  epoch:{},\n",
        "  loss_D:{},\n",
        "loss_G :{},\n",
        "loss_G_GAN:{},\n",
        "loss_G_cycle :{},\n",
        "loss_G_identity:{},\n",
        "   \"\"\".format(epoch, running_loss_D,running_loss_G,\n",
        "              running_loss_G_GAN, running_loss_G_cycle, running_loss_G_identity)\n",
        "  print(loss_log)\n",
        "  fake_imgs = torch.cat([fake_img_A, fake_img_B])\n",
        "  grid_imgs = vutils.make_grid(fake_imgs.detach())\n",
        "  grid_imgs_arr = grid_imgs.cpu().numpy()\n",
        "  plt.imshow(np.transpose(grid_imgs_arr, (1,2,0)))\n",
        "  plt.show()\n",
        " # model_list = [netG_A2B, netG_B2A, netD_A, netD_B]\n",
        "  #model_name_list = [\"netG_A2B\", \"netG_B2A\", \"netD_A\", \"netD_B\"]\n",
        "  #save_params(epoch, f_path_params, model_list, model_name_list)"
      ],
      "metadata": {
        "id": "-yVkMzj3Bu-c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "399ea84a-7c35-4013-f537-daf094af9394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|                                                                                         | 0/1334 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TjoXL9AObeqb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}